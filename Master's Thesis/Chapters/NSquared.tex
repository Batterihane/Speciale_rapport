\chapter{The $O(n^2)$ algorithm}
Goddard et. al.\cite{nsquared} describes a $O(n^2)$ algorithm for finding the maximum agreement subtree for two rooted binary trees. Given the two trees $T_a$ and $T_w$ each of size n, the idea is to iteratively find the largest agreement subtree and its size for every pair of subtrees from $T_a$ and $T_w$. This can be done in quadratic time by using an algorithm based on Lemma 1. Note that the algorithm also works when $T_a$ and $T_w$ does not have the same leaf set.

\begin{Lemma}
	Let $T_a$ be a tree rooted at node a with the children b and c; And let $T_w$ be rooted at w with children x and y. We now define $\#(T_a,T_w)$ as the size of the maximum agreement subtree of $T_a$ and $T_w$.  $\#(T_a,T_w)$ is given by the maximum of the following six numbers: \#$(T_b,T_x)+(T_c,T_y)$,
	\#$(T_b,T_y)+(T_c,T_x)$,
	\#$(T_a,T_x)$,
	\#$(T_a,T_y)$,
	\#$(T_b,T_w)$,
	\#$(T_c,T_w)$.\\
	\textbf{Proof.}\\
	This is a proof by case over the possible subtrees contributing to the agreement subtree $A_{aw}$ for $T_a$ and $T_w$.\\
	\underline{Case 1}: Only $T_b$ of $T_a$ contributes to $A_{aw}$.
	If this is the case, then the agreement subtree can only exist between $T_b$ and $T_w$, \#$(T_b,T_w)$.\\
	\underline{Case 2}: Only $T_c$ of $T_a$ contributes to $A_{aw}$.
	If this is the case, then the agreement subtree can only exist between $T_c$ and $T_w$,
	\#$(T_c,T_w)$.\\
	\underline{Case 3}: Only $T_x$ of $T_w$ contributes to $A_{aw}$.
	If this is the case, then the agreement subtree can only exist between $T_x$ and $T_a$,
	\#$(T_a,T_x)$.\\
	\underline{Case 4}: Only $T_y$ of $T_w$ contributes to $A_{aw}$.
	If this is the case, then the agreement subtree can only exist between $T_y$ and $T_a$,
	\#$(T_a,T_y)$.\\
	\underline{Case 5}: This case covers all that case 1 through 4 doesn't, which means that all children b, c, x and y contibute to the MAST.
	Consider the agreement tree, $A_r$, rooted in r and with children s and t. We claim the following: A child of r cannot contain a leaf, $b'$, from $T_b$ and a leaf, $c'$, from $T_c$ at the same time.\\
	If this is the case, then we only need to find the MAST size of child pairing permutations across $T_a\ and\ T_w$: $max\{\#(T_b, T_x)+\#(T_c, T_y), \#(T_b, T_y)+\#(T_c, T_x)\}$.
	
	Let us now prove our claim by assuming that it doesn't hold, and use that to reach a  contradiction. Suppose that $A_s$ contains a leaf , $b'$, from $T_b$ and a leaf, $c'$, from $T_c$. Let $f$ be any leaf from $A_t$. Assume that $f$ is from $T_b$ (the other case is identical). We now see that the subtree induced by $b'$, $f$ and $c'$ differs for $A_r$ and $T_a$ as illustrated in Figure \ref{Fig:Lemma1Binary}. This is clearly contradictory to the definition of an agreement tree, which is why we must conclude our claim to be correct.
	\qed   	  
\end{Lemma}

\begin{figure}
	\begin{enumerate}
		
		\item[]  \Tree [.r [.s b' c' ].s [.t f ].t ].r
		\hskip 0.4in
		 \Tree [.a [.b b' f ].b [.c c' ].c ].a
		
	\end{enumerate}	
	
	\caption{Two binary trees with different topology, induced by the same leaves.}
	\label{Fig:Lemma1Binary}	
\end{figure}


What Lemma 1 essentially states is twofold. First, if the MAST contains leaves from all subtrees ($T_b$,$T_c$,$T_x$,$T_y$), then its size is given by the two largest distinct agreement matchings between pairs of these. Secondly, if the MAST does not include all subtrees, then its size is given by the largest agreement matching between $T_a$ and $T_w$ where one of the subtrees is excluded.
This gives rise to a recursive solution for finding the size of the maximum agreement subtree. The recursive function is defined in figure \ref{Fig:Function1}.

\begin{figure}
	\begin{equation*}
	\begin{aligned}
	f(T_a,T_w)=max
	\begin{cases}
	f(T_b,T_x)+f(T_c,T_y) & \text{if $a$ and $w$ are both internal nodes}
	\\
	f(T_b,T_y)+f(T_c,T_x) & \text{if $a$ and $w$ are both internal nodes}
	\\
	f(T_a, T_x)           & \text{if $w$ is an internal node}
	\\
	f(T_a, T_y)           & \text{if $w$ is an internal node}
	\\
	f(T_b, T_w)           & \text{if $a$ is an internal node}
	\\
	f(T_c, T_w)           & \text{if $a$ is an internal node}
	\\
	1 	                  & \text{if $a$ and $w$ are both leaves and  $a$=$w$}
	\\
	0                     
	\end{cases}
	\end{aligned}
	\phantom{\hspace{6cm}}
	\end{equation*}
	\caption{Recursive MAST size function}
	\label{Fig:Function1}
\end{figure}


Like many similar recursive definitions in bioinformatics, we run into the problem that the recursive function computes the same partial results multiple times. This problem is rectified by the method of dynamic programming. Specifically, we wish to store the partial results in a $O(|T_a|) \times O(|T_w|)$ table containing a row for each node in the first tree and a column for each node in the second tree. We seek to fill out the table row by row with our partial results, starting from the top left corner, such that a cell corresponding to two nodes contains the size of the maximum agreement subtree between the subtrees rooted at these two nodes. In the end, the size of the maximum agreement subtree should be stored in the bottom right corner.
Looking at the function in figure \ref{Fig:Function1} we see that the partial result for each tree pair is dependent on the results for their subtrees. This implies that we must list the table nodes in postorder, thereby ensuring that the partial results, on which a given node is dependent, have already been calculated when we reach it. 
By introducing such a table we also introduce a requirement of $O(n^2)$ space and time, making it a quadratic algorithm. Simple techniques for reducing the space requirement, like only storing a few number of rows in the table at a time, cannot be applied in this case, since the computation of a new row may depend on any of the previous rows.  

\section{Algorithm example}
Two example trees have been provided in figure \ref{Fig:Binary1}. We now wish to compute the size of their maximum agreement subtree using the agorithm described above. For this reason, we create a $15 \times 15$ table, where the rows and columns correspond to the nodes of each tree in postorder. Using the function described in \ref{Fig:Function1}, we can now fill out the table row wise starting from the topmost row. The resulting table can be seen in \ref{Table:Table1}, where we from the bottom right corner see that the maximum size of the MAST is 6. We can conclude that 6 is indeed correct, since removing only one leaf cannot produce an agreement tree in this case, while removing $leaf_1$ and $leaf_7$ will produce the desired agreement tree of size 6. Their MAST is likewise displayed in figure \ref{Fig:Binary1}. 

\begin{figure}
	
	\begin{itemize}
		\setlength\itemsep{3em}
		\item[] \Tree [.A [.B [.C leaf_1 leaf_2 ] [.D leaf_3 leaf_4 ] ].B [.E [.F leaf_5 leaf_6 ] [.G leaf_7 leaf_8 ] ].E ].A
		
		\item[]
		\Tree [.H [.I [.J leaf_1  leaf_8 ] [.L leaf_5 leaf_6 ] ].I [.M [.N leaf_2 leaf_7 ] [.F leaf_3 leaf_4 ] ].M ].H
		
		\item[]
		\Tree [.A [.B leaf_2 [.D leaf_3 leaf_4 ] ].B [.E [.F leaf_5 leaf_6 ] leaf_8 ].E ].A
	\end{itemize}	
	
	\caption{Two example binary trees and their resulting MAST}
	\label{Fig:Binary1}	
\end{figure}


\begin{table}[]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		\textbf{}        & $\mathbf{leaf_1}$ & $\mathbf{leaf_2}$ & \textbf{C} & \textbf{...} & \textbf{G} & \textbf{E} & \textbf{A} \\ \hline
		$\mathbf{leaf_1}$ & 1                & 0                & 1          & ...            & 0          & 0          & 1          \\ \hline
		$\mathbf{leaf_8}$ & 0                & 0                & 0          & ...            & 1          & 1          & 1          \\ \hline
		\textbf{J}       & 1                & 0                & 1          & ...            & 1          & 1          & 2          \\ \hline
		\textbf{...}     & ...              & ...              & ...        & ...            & ...        & ...        & ...        \\ \hline
		\textbf{F}       & 0                & 0                & 0          & ...            & 0          & 0          & 2          \\ \hline
		\textbf{M}       & 0                & 1                & 1          & ...            & 1          & 1          & 3          \\ \hline
		\textbf{H}       & 1                & 1                & 2          & ...            & 2          & 3          & 6          \\ \hline
	\end{tabular}
	
	\caption{Score Matrix for the trees in figure \ref{Fig:Binary1}}
	\label{Table:Table1}
\end{table}

We will in the following sections show how one can extend this method for calculating the size of the MAST to computing the actual tree.


\section{Computing the MAST}
Extending the solution for computing the size of the MAST to include the computation of the actual MAST is fairly simple in this case. We found two different ways of going about it. 
\\
\\
\textbf{Option 1: Continual Tree Construction} \\
The first option is to extend the size algorithm simply by, for each cell in the table, attaching the MAST responsible for that size. This cannot be done by copying subtrees from the input trees, since that would break our time constraints. For this reason, a cell instead stores either a leaf or a node with pointers to its children, and hence mutiple cells/masts will refer to the same subtrees. This means that we will end up creating a Directed Acyclic Graph, where the root node of the MAST is saved in the bottom right corner of the size table. Finally a traversal of the tree, separating it from the DAG is needed.
More concretely, the algorithm is described as follows: 

For each pair of nodes $p$ and $q$, one from each input tree, we compute the agreement subtree $A_{p,q}$ for the two subtrees $T_p$ and $T_q$ having respectively $p$ and $q$ as roots. For such a pair of nodes there are three cases.

The first case is that $p$ and $q$ are both leaves. If the leaves are equal, i.e. they have the same name, then $A_{p,q}$ will be the tree consisting of exactly one leaf with that name. Otherwise $A_{p,q}$ is empty.

The second case is that we have a leaf and an internal node. Let's say $q$ is the internal node having $x$ and $y$ as children. If the leaf corresponding to $p$ is contained in $T_q$, it will also be contained in either $T_x$ or $T_y$ and $A_{p,q}$ will be the same as either $A_{p,x}$ or $A_{p,y}$. Since we do a postorder traversal of the trees, $A_{p,x}$ and $A_{p,y}$ have already been computed and $A_{p,q}$ can just be set to the largest of the two.

The third case is that both $p$ and $q$ are internal nodes, where $p$ have children $b$ and $c$ and $q$ have children $x$ and $y$. In this case we can use Lemma 1 and determine which of the six cases gives the largest size. Again, all the agreement subtrees to consider have already been computed. If the largest size is $\#A_{b,x} + \#A_{c,y}$, then $A_{p,q}$ will be a tree where the root has the roots of $A_{b,x}$ and $A_{c,y}$ as children. Similarly if the largest size is $\#A_{b,y} + \#A_{c,x}$.\\
\\
\textbf{Option 2: Recursive Backtracking} \\
While the first option is fairly simple to implement and understand, it can consume quite a bit of memory due to the trees we save that ultimately end up being irrelevant for the final result. Backtracking tries to rectify this problem by only computing and storing exactly the relevant subtrees for the final MAST. This is done by observing that the function in figure \ref{Fig:Function1}, on which the algorithm is based, is a maximization function. Therefore, the table is deterministically constructed, allowing us, for each cell, to determine what cells were responsible for the size it contains. By computing the entire size table first, we can start with the bottom right cell and recursively run back through the table determining all cells responsible for the MAST size. The tree is then constructed following the same logic used in Option 1. 
\\
Java inspired pseudo-code for the backtracking algorithm can be seen in Figure \ref{Code:Backtracking1}. Notice that the order of the if-cases in the pseudo code are significant, which was not previously the case when only computing the MAST size. The reason is simply that several of the cases might actually lead to the same MAST size, but not all will lead to a valid binary tree. For instance the second and third recursive case might lead to the same size, which means that at least one subtree does not contribute to the MAST. Choosing the third case therefore means that we end up producing a null-branch in the MAST, since this branch does not contribute to the MAST size. 
    
\begin{figure}
	\begin{lstlisting}[language=Java]
	Function RecBackTrack(Root1, Root2, ScoreMatrix)	{
	  int Score = ScoreMatrix[Root1][Root2];
	  
	  /* Base Case */
	  if (Type(Root1) = Type(Root2) = Leaf) {
	    return Root1 = Root2 ? Root1 : null; 
	  }
	  
	  /* Recursive Case 1 */
	  if (Type(Root1) = InternalNode) {
	    int Score1 = ScoreMatrix[Root1.Child1][Root2]; 
	    int Score2 = ScoreMatrix[Root1.Child2][Root2];
	  
	    if (Score = Score1) {
	      return RecBackTrack(Root1.Child1, Root2);
	    }
	    else if (Score = Score2) {
	      return RecBackTrack(Root1.Child2, Root2);
	    }
	  }
	  
	  /* Recursive Case 2 */
	  if (Type(Root2) = InternalNode) {
	    int Score1 = ScoreMatrix[Root1][Root2.Child1]; 
	    int Score2 = ScoreMatrix[Root1][Root2.Child2];
	  
	    if (Score = Score1) {
	      return RecBackTrack(Root1, Root2.Child1);
	    }
	    else if (Score = Score2) {
	      return RecBackTrack(Root1, Root2.Child2);
	    }
	  }	
	  
	  /* Recursive Case 3 */
	  if(Type(Root1) = Type(Root2) = InternalNode) {
	    int Score1 = ScoreMatrix[Root1.Child1][Root2.Child1];
	    int Score2 = ScoreMatrix[Root1.Child2][Root2.Child2];
	    int Score3 = ScoreMatrix[Root1.Child1][Root2.Child2];
	    int Score4 = ScoreMatrix[Root1.Child2][Root2.Child1];
	
	    if(Score = Score1 + Score2) {
	      Tree subTree1 = RecBackTrack(Root1.Child1, Root2.Child1);
	      Tree subTree2 = RecBackTrack(Root1.Child2, Root2.Child2);
	      return /*internal node with subTree1 and 
	        subTree2 as children */
	    }
	    else if (Score1 = Score3 + Score4) {
	      Tree subTree1 = RecBackTrack(Root1.Child1, Root2.Child2);
          Tree subTree2 = RecBackTrack(Root1.Child2, Root2.Child1);
	      return /*internal node with subTree1 and 
	        subTree2 as children */
	    }
	  }
	}
	\end{lstlisting}
	\caption{Java pseudo code for BackTracking}
	\label{Code:Backtracking1}
\end{figure}	

\section{Evaluation}
All in all, the $O(n^2)$ algorithm is fairly simple to implement and understand, but it also has its practical limitations when working with large trees. As we will see in the experiments section, the algorithm starts having trouble with binary trees of size larger than 6000 in terms of time and memory consumption. The main problem with the algorithm is that it considers too many combinations of subtrees that end up being irrelevant. Effectively most of the time spent filling out the size table is wasted. In our previous example of filling out the size table of 225 cells, only 25 cells ended up ultimately having an impact on the produced MAST, since those were the only ones accesed by the backtracking algorithm. The $O(nlogn)$ algorithm that we are about to examine improves on the 'wasted' work by only considering more relevant information between subtrees.
Similarly to the naive algorithm, there are no worst-case or best-case trees to consider, since we always fill out the entire size table despite what the tree topology might look like. 
